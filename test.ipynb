{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrzVOGWJBuVM",
        "outputId": "dc69dd3b-5031-4ff8-fd2c-64e55f83215f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n7KJt3Sw0ARq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, models\n",
        "\n",
        "\n",
        "class CUB200Dataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None, apply_bg_removal=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform or self.default_transform()\n",
        "        self.apply_bg_removal = apply_bg_removal\n",
        "\n",
        "        # Load metadata\n",
        "        self.data = self.load_metadata()\n",
        "\n",
        "    def load_metadata(self):\n",
        "        split_file = os.path.join(self.root_dir, f'{self.split}.txt')\n",
        "        data = pd.read_csv(split_file, sep=' ', names=['filename', 'label'])\n",
        "        data['filepath'] = data['filename'].apply(lambda x: os.path.join(self.root_dir, self.split, x))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.loc[idx, 'filepath']\n",
        "        image = self.load_image(img_name)\n",
        "\n",
        "        # Apply transformations to convert the cropped image to a tensor\n",
        "        image = self.transform(image)\n",
        "\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        return image, label\n",
        "\n",
        "    @staticmethod\n",
        "    def load_image(image_path):\n",
        "        try:\n",
        "            return Image.open(image_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def default_transform(self):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UYskNTDu-grs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms, models\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "# Define transformations\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CUB200Dataset(root_dir='drive/MyDrive/COS30082_preprocessed', split='train', transform=train_transforms)\n",
        "test_dataset = CUB200Dataset(root_dir='drive/MyDrive/COS30082_preprocessed', split='test', transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "RTjH6Y_rjRHs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Sz6EKXfc-j6x"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class BirdClassifier(nn.Module):\n",
        "    def __init__(self, model_name='efficientnet_b5', num_classes=200):\n",
        "        super(BirdClassifier, self).__init__()\n",
        "\n",
        "        # Choose the model based on the input argument 'model_name'\n",
        "        if model_name == 'resnet50':\n",
        "            self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "            in_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Sequential(\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'resnext50_32x4d':\n",
        "            self.model = models.resnext50_32x4d(weights=models.ResNeXt50_32X4D_Weights.DEFAULT)\n",
        "            in_features = self.model.fc.in_features\n",
        "            self.model.fc = nn.Sequential(\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            self.model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
        "            in_features = self.model.classifier[1].in_features\n",
        "            self.model.classifier = nn.Sequential(\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b5':\n",
        "            self.model = models.efficientnet_b5(weights=models.EfficientNet_B5_Weights.DEFAULT)\n",
        "            in_features = self.model.classifier[1].in_features\n",
        "            self.model.classifier = nn.Sequential(\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(in_features, num_classes)\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model_name: {model_name}. Choose from 'resnet50', 'resnext50_32x4d', 'efficientnet_b0', 'efficientnet_b5'.\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# 5. Setup Model, Criterion, Optimizer, and Scheduler\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# To use EfficientNet B5\n",
        "model = BirdClassifier(model_name='efficientnet_b5', num_classes=200)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Br1g8opWfQXu"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience  # How many epochs to wait after last improvement\n",
        "        self.delta = delta  # Minimum change to qualify as an improvement\n",
        "        self.best_loss = None  # Best validation loss seen so far\n",
        "        self.counter = 0  # Tracks how long since the last improvement\n",
        "        self.early_stop = False  # Flag to indicate whether training should stop\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0  # Reset counter if validation loss improves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tJH7pYI5fQXv"
      },
      "outputs": [],
      "source": [
        "# 6. Training and Evaluation Functions\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total_images = 0\n",
        "\n",
        "    for images, labels in tqdm(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total_images += labels.size(0)\n",
        "\n",
        "    train_accuracy = (correct / total_images) * 100\n",
        "    return running_loss / len(loader.dataset), train_accuracy\n",
        "\n",
        "def evaluate(model, loader, criterion, device, num_classes=200):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_top1 = 0\n",
        "    total_images = 0\n",
        "\n",
        "    # Track per-class accuracy\n",
        "    class_correct = torch.zeros(num_classes).to(device)\n",
        "    class_total = torch.zeros(num_classes).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted_top1 = torch.max(outputs, 1)\n",
        "            correct_top1 += (predicted_top1 == labels).sum().item()\n",
        "            total_images += labels.size(0)\n",
        "\n",
        "            # Track per-class accuracy\n",
        "            for label, prediction in zip(labels, predicted_top1):\n",
        "                class_correct[label] += (prediction == label).item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    # Calculate average accuracy per class\n",
        "    avg_class_accuracy = (class_correct / class_total).mean().item() * 100\n",
        "    overall_accuracy = (correct_top1 / total_images) * 100\n",
        "\n",
        "    return running_loss / len(loader.dataset), overall_accuracy, avg_class_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Y-L5cMpi-rZQ",
        "outputId": "5066f512-b561-442b-b0a0-6aebc68363e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 82/302 [02:23<06:26,  1.76s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-14252c390589>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_class_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b76a73d83a73>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# 7. Training Loop with Early Stopping and Class Accuracy\n",
        "num_epochs = 10\n",
        "best_acc = 0.0\n",
        "early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, avg_class_acc = evaluate(model, test_loader, criterion, device, num_classes=200)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f} | Train Accuracy: {train_acc:.2f}% | Validation Accuracy: {val_acc:.2f}%\")\n",
        "    print(f\"Average Accuracy per Class: {avg_class_acc:.2f}%\")\n",
        "\n",
        "    # Save the best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(\"Model saved!\")\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopper(val_loss)\n",
        "    if early_stopper.early_stop:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LrX3nyglfQX0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Assuming you have your model architecture and test_dataloader already defined\n",
        "# Also assuming your checkpoint file path is 'best_model_b5.pth'\n",
        "\n",
        "# Load your model (make sure to initialize the model architecture before loading)\n",
        "checkpoint_path = 'best_model_b5_newdataset.pth'  # Replace with the actual path to your checkpoint\n",
        "model = BirdClassifier(model_name='efficientnet_b5', num_classes=200) # Initialize the model first\n",
        "\n",
        "# Load the checkpoint\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path, weights_only=True)\n",
        "# Load the state_dict into the model\n",
        "model.load_state_dict(checkpoint) # Directly load the state_dict\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Assuming you're using GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Initialize variables to track performance\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable gradient calculation for efficiency\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move inputs and labels to the appropriate device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(inputs)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        # Track total correct predictions and total samples\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        # Optionally store predictions and labels for further analysis\n",
        "        all_predictions.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy on test set: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oigi7ACjVHQ",
        "outputId": "e49c8b14-d475-4ec6-b4d4-628076c712b6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.7849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "# Assuming you have the test_loader, model, and criterion defined\n",
        "model.eval()\n",
        "running_loss = 0.0\n",
        "correct_top1 = 0\n",
        "total_images = 0\n",
        "\n",
        "# Assuming you know the number of classes\n",
        "num_classes = 200  # Replace with the actual number of classes\n",
        "\n",
        "# Track per-class accuracy\n",
        "class_correct = torch.zeros(num_classes).to(device)\n",
        "class_total = torch.zeros(num_classes).to(device)\n",
        "\n",
        "# Track overall performance\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass to get outputs\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Get top-1 predictions\n",
        "        _, predicted_top1 = torch.max(outputs, 1)\n",
        "\n",
        "        # Track correct predictions for overall accuracy\n",
        "        correct_top1 += (predicted_top1 == labels).sum().item()\n",
        "        total_images += labels.size(0)\n",
        "\n",
        "        # Track per-class accuracy\n",
        "        for label, prediction in zip(labels, predicted_top1):\n",
        "            class_correct[label] += (prediction == label).item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "        # Optionally store predictions and labels for further analysis\n",
        "        all_predictions.extend(predicted_top1.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = (correct_top1 / total_images) * 100\n",
        "print(f'Overall Accuracy on test set: {overall_accuracy:.4f}%')\n",
        "\n",
        "# Calculate average accuracy per class\n",
        "class_accuracies = class_correct / class_total\n",
        "avg_class_accuracy = class_accuracies.mean().item() * 100\n",
        "print(f'Average Class Accuracy: {avg_class_accuracy:.4f}%')\n",
        "\n",
        "# Print per-class accuracy\n",
        "for i in range(num_classes):\n",
        "    print(f'Accuracy of class {i}: {class_accuracies[i] * 100:.2f}%')\n",
        "\n",
        "# Calculate the average loss\n",
        "avg_loss = running_loss / total_images\n",
        "print(f'Average Loss: {avg_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUnQyfqLmTK_",
        "outputId": "00f60c44-b298-40ff-affe-8e89a0078c78"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:22<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy on test set: 78.4884%\n",
            "Average Class Accuracy: 78.0077%\n",
            "Accuracy of class 0: 57.14%\n",
            "Accuracy of class 1: 100.00%\n",
            "Accuracy of class 2: 80.00%\n",
            "Accuracy of class 3: 100.00%\n",
            "Accuracy of class 4: 80.00%\n",
            "Accuracy of class 5: 100.00%\n",
            "Accuracy of class 6: 100.00%\n",
            "Accuracy of class 7: 83.33%\n",
            "Accuracy of class 8: 20.00%\n",
            "Accuracy of class 9: 80.00%\n",
            "Accuracy of class 10: 80.00%\n",
            "Accuracy of class 11: 100.00%\n",
            "Accuracy of class 12: 100.00%\n",
            "Accuracy of class 13: 100.00%\n",
            "Accuracy of class 14: 100.00%\n",
            "Accuracy of class 15: 83.33%\n",
            "Accuracy of class 16: 60.00%\n",
            "Accuracy of class 17: 100.00%\n",
            "Accuracy of class 18: 71.43%\n",
            "Accuracy of class 19: 100.00%\n",
            "Accuracy of class 20: 100.00%\n",
            "Accuracy of class 21: 25.00%\n",
            "Accuracy of class 22: 60.00%\n",
            "Accuracy of class 23: 50.00%\n",
            "Accuracy of class 24: 83.33%\n",
            "Accuracy of class 25: 80.00%\n",
            "Accuracy of class 26: 100.00%\n",
            "Accuracy of class 27: 85.71%\n",
            "Accuracy of class 28: 0.00%\n",
            "Accuracy of class 29: 66.67%\n",
            "Accuracy of class 30: 71.43%\n",
            "Accuracy of class 31: 66.67%\n",
            "Accuracy of class 32: 57.14%\n",
            "Accuracy of class 33: 60.00%\n",
            "Accuracy of class 34: 83.33%\n",
            "Accuracy of class 35: 87.50%\n",
            "Accuracy of class 36: 71.43%\n",
            "Accuracy of class 37: 57.14%\n",
            "Accuracy of class 38: 50.00%\n",
            "Accuracy of class 39: 33.33%\n",
            "Accuracy of class 40: 85.71%\n",
            "Accuracy of class 41: 100.00%\n",
            "Accuracy of class 42: 57.14%\n",
            "Accuracy of class 43: 50.00%\n",
            "Accuracy of class 44: 100.00%\n",
            "Accuracy of class 45: 85.71%\n",
            "Accuracy of class 46: 80.00%\n",
            "Accuracy of class 47: 85.71%\n",
            "Accuracy of class 48: 57.14%\n",
            "Accuracy of class 49: 100.00%\n",
            "Accuracy of class 50: 83.33%\n",
            "Accuracy of class 51: 66.67%\n",
            "Accuracy of class 52: 100.00%\n",
            "Accuracy of class 53: 100.00%\n",
            "Accuracy of class 54: 80.00%\n",
            "Accuracy of class 55: 100.00%\n",
            "Accuracy of class 56: 75.00%\n",
            "Accuracy of class 57: 80.00%\n",
            "Accuracy of class 58: 60.00%\n",
            "Accuracy of class 59: 85.71%\n",
            "Accuracy of class 60: 80.00%\n",
            "Accuracy of class 61: 20.00%\n",
            "Accuracy of class 62: 75.00%\n",
            "Accuracy of class 63: 60.00%\n",
            "Accuracy of class 64: 83.33%\n",
            "Accuracy of class 65: 50.00%\n",
            "Accuracy of class 66: 80.00%\n",
            "Accuracy of class 67: 60.00%\n",
            "Accuracy of class 68: 85.71%\n",
            "Accuracy of class 69: 100.00%\n",
            "Accuracy of class 70: 100.00%\n",
            "Accuracy of class 71: 83.33%\n",
            "Accuracy of class 72: 100.00%\n",
            "Accuracy of class 73: 85.71%\n",
            "Accuracy of class 74: 85.71%\n",
            "Accuracy of class 75: 100.00%\n",
            "Accuracy of class 76: 85.71%\n",
            "Accuracy of class 77: 100.00%\n",
            "Accuracy of class 78: 50.00%\n",
            "Accuracy of class 79: 80.00%\n",
            "Accuracy of class 80: 100.00%\n",
            "Accuracy of class 81: 85.71%\n",
            "Accuracy of class 82: 100.00%\n",
            "Accuracy of class 83: 75.00%\n",
            "Accuracy of class 84: 100.00%\n",
            "Accuracy of class 85: 100.00%\n",
            "Accuracy of class 86: 100.00%\n",
            "Accuracy of class 87: 100.00%\n",
            "Accuracy of class 88: 100.00%\n",
            "Accuracy of class 89: 83.33%\n",
            "Accuracy of class 90: 33.33%\n",
            "Accuracy of class 91: 83.33%\n",
            "Accuracy of class 92: 100.00%\n",
            "Accuracy of class 93: 100.00%\n",
            "Accuracy of class 94: 100.00%\n",
            "Accuracy of class 95: 85.71%\n",
            "Accuracy of class 96: 85.71%\n",
            "Accuracy of class 97: 83.33%\n",
            "Accuracy of class 98: 100.00%\n",
            "Accuracy of class 99: 100.00%\n",
            "Accuracy of class 100: 80.00%\n",
            "Accuracy of class 101: 85.71%\n",
            "Accuracy of class 102: 80.00%\n",
            "Accuracy of class 103: 83.33%\n",
            "Accuracy of class 104: 75.00%\n",
            "Accuracy of class 105: 100.00%\n",
            "Accuracy of class 106: 80.00%\n",
            "Accuracy of class 107: 100.00%\n",
            "Accuracy of class 108: 66.67%\n",
            "Accuracy of class 109: 100.00%\n",
            "Accuracy of class 110: 85.71%\n",
            "Accuracy of class 111: 83.33%\n",
            "Accuracy of class 112: 71.43%\n",
            "Accuracy of class 113: 100.00%\n",
            "Accuracy of class 114: 57.14%\n",
            "Accuracy of class 115: 50.00%\n",
            "Accuracy of class 116: 57.14%\n",
            "Accuracy of class 117: 83.33%\n",
            "Accuracy of class 118: 83.33%\n",
            "Accuracy of class 119: 71.43%\n",
            "Accuracy of class 120: 85.71%\n",
            "Accuracy of class 121: 80.00%\n",
            "Accuracy of class 122: 28.57%\n",
            "Accuracy of class 123: 100.00%\n",
            "Accuracy of class 124: 85.71%\n",
            "Accuracy of class 125: 100.00%\n",
            "Accuracy of class 126: 71.43%\n",
            "Accuracy of class 127: 80.00%\n",
            "Accuracy of class 128: 87.50%\n",
            "Accuracy of class 129: 100.00%\n",
            "Accuracy of class 130: 75.00%\n",
            "Accuracy of class 131: 80.00%\n",
            "Accuracy of class 132: 85.71%\n",
            "Accuracy of class 133: 85.71%\n",
            "Accuracy of class 134: 80.00%\n",
            "Accuracy of class 135: 80.00%\n",
            "Accuracy of class 136: 83.33%\n",
            "Accuracy of class 137: 57.14%\n",
            "Accuracy of class 138: 100.00%\n",
            "Accuracy of class 139: 75.00%\n",
            "Accuracy of class 140: 42.86%\n",
            "Accuracy of class 141: 75.00%\n",
            "Accuracy of class 142: 75.00%\n",
            "Accuracy of class 143: 0.00%\n",
            "Accuracy of class 144: 40.00%\n",
            "Accuracy of class 145: 60.00%\n",
            "Accuracy of class 146: 100.00%\n",
            "Accuracy of class 147: 100.00%\n",
            "Accuracy of class 148: 83.33%\n",
            "Accuracy of class 149: 60.00%\n",
            "Accuracy of class 150: 60.00%\n",
            "Accuracy of class 151: 85.71%\n",
            "Accuracy of class 152: 85.71%\n",
            "Accuracy of class 153: 71.43%\n",
            "Accuracy of class 154: 85.71%\n",
            "Accuracy of class 155: 85.71%\n",
            "Accuracy of class 156: 66.67%\n",
            "Accuracy of class 157: 83.33%\n",
            "Accuracy of class 158: 85.71%\n",
            "Accuracy of class 159: 100.00%\n",
            "Accuracy of class 160: 100.00%\n",
            "Accuracy of class 161: 71.43%\n",
            "Accuracy of class 162: 71.43%\n",
            "Accuracy of class 163: 80.00%\n",
            "Accuracy of class 164: 100.00%\n",
            "Accuracy of class 165: 100.00%\n",
            "Accuracy of class 166: 100.00%\n",
            "Accuracy of class 167: 50.00%\n",
            "Accuracy of class 168: 80.00%\n",
            "Accuracy of class 169: 71.43%\n",
            "Accuracy of class 170: 75.00%\n",
            "Accuracy of class 171: 66.67%\n",
            "Accuracy of class 172: 50.00%\n",
            "Accuracy of class 173: 83.33%\n",
            "Accuracy of class 174: 100.00%\n",
            "Accuracy of class 175: 71.43%\n",
            "Accuracy of class 176: 100.00%\n",
            "Accuracy of class 177: 40.00%\n",
            "Accuracy of class 178: 0.00%\n",
            "Accuracy of class 179: 57.14%\n",
            "Accuracy of class 180: 33.33%\n",
            "Accuracy of class 181: 75.00%\n",
            "Accuracy of class 182: 100.00%\n",
            "Accuracy of class 183: 66.67%\n",
            "Accuracy of class 184: 71.43%\n",
            "Accuracy of class 185: 57.14%\n",
            "Accuracy of class 186: 83.33%\n",
            "Accuracy of class 187: 100.00%\n",
            "Accuracy of class 188: 100.00%\n",
            "Accuracy of class 189: 75.00%\n",
            "Accuracy of class 190: 100.00%\n",
            "Accuracy of class 191: 87.50%\n",
            "Accuracy of class 192: 71.43%\n",
            "Accuracy of class 193: 40.00%\n",
            "Accuracy of class 194: 71.43%\n",
            "Accuracy of class 195: 60.00%\n",
            "Accuracy of class 196: 33.33%\n",
            "Accuracy of class 197: 80.00%\n",
            "Accuracy of class 198: 71.43%\n",
            "Accuracy of class 199: 100.00%\n",
            "Average Loss: 0.9441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}